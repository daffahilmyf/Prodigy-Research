{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = [\n",
    "    \"The driver can not speak in a group call until permission is granted by the network after pushing the PTT button.\",\n",
    "    \"If the specimen/sample was created from another specimen/sample (e.g., aliquots, and new specimen types created from a source sample), laboratory results for the child specimens/samples must be linked to the corresponding parent specimen/sample.\"\n",
    "    \"The subject of a specimen/sample collected for laboratory testing must be linked to the specimen/sample by an identifier (i.e., Subject ID) that is unique within the jurisdiction.\",\n",
    "    \"Travel history data should include information such as the method of transportation (e.g. bus, plane, boat, car), flight number, departure and arrival dates and times, and the origination and destination locations (city, state, and country).\",\n",
    "    \"OM data should be synchronized so that all instances of OM applications working from the same server are able to share and use the same data.\",\n",
    "    \"If the on-board has no valid national values for the current location, default values shall be used by the onboard equipment.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NONE': 0.0021604986395686865, 'PRECONDITION': 0.000748162274248898, 'POSTCONDITION': 0.8850841522216797, 'BOTH': 0.11200714856386185}\n",
      "{'NONE': 6.60339901514817e-06, 'PRECONDITION': 5.791108392827482e-08, 'POSTCONDITION': 0.024815978482365608, 'BOTH': 0.9751773476600647}\n",
      "{'NONE': 1.584843994351104e-05, 'PRECONDITION': 4.883850124315359e-06, 'POSTCONDITION': 0.04082644730806351, 'BOTH': 0.95915287733078}\n",
      "{'NONE': 0.0010280328569933772, 'PRECONDITION': 0.00047738946159370244, 'POSTCONDITION': 0.9603550434112549, 'BOTH': 0.038139473646879196}\n",
      "{'NONE': 0.004482630640268326, 'PRECONDITION': 0.0014781344216316938, 'POSTCONDITION': 0.19321559369564056, 'BOTH': 0.8008236289024353}\n"
     ]
    }
   ],
   "source": [
    "model = spacy.load(\"./training/prodigy/textcat/model-best\")\n",
    "for item in range(len(data_test)):\n",
    "    doc = model(data_test[item])\n",
    "    print(doc.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NONE': 0.0021604986395686865, 'PRECONDITION': 0.000748162274248898, 'POSTCONDITION': 0.8850841522216797, 'BOTH': 0.11200714856386185}\n"
     ]
    }
   ],
   "source": [
    "doc = model(\"The driver can not speak in a group call until permission is granted by the network after pushing the PTT button.\")\n",
    "print(doc.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NONE': 0.0011083845747634768, 'PRECONDITION': 0.00014246517093852162, 'POSTCONDITION': 0.8670791983604431, 'BOTH': 0.13166993856430054}\n"
     ]
    }
   ],
   "source": [
    "doc = model(\"The subject of a specimen/sample collected for laboratory testing must be linked to the specimen/sample by an identifier (i.e., Subject ID) that is unique within the jurisdiction.\")\n",
    "print(doc.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NONE': 0.37016069889068604, 'PRECONDITION': 0.004506803583353758, 'POSTCONDITION': 0.324388712644577, 'BOTH': 0.3009437024593353}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prodigy.components.db import connect\n",
    "\n",
    "db = connect()\n",
    "all_dataset_names = db.datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement ap_params (from versions: none)\n",
      "ERROR: No matching distribution found for ap_params\n"
     ]
    }
   ],
   "source": [
    "%pip install ap_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ap_params import replace_abbreviations\n",
    "\n",
    "# Open the input and output files\n",
    "with open(\"./assets/merged.jsonl\", \"r\") as input_file, open(\"./assets/normalized.jsonl\", \"w\") as output_file:\n",
    "    # Read each line of the input file\n",
    "    for line in input_file:\n",
    "        # Load the line as a JSON object\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        data[\"text\"] = data[\"text\"]\n",
    "        \n",
    "        # Write the modified object back to the output file\n",
    "        output_file.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./assets/preprocess/combination-T-T-T-T.jsonl\", \"r\") as input_file, open(\"./assets/normalized_1.jsonl\", \"w\") as output_file:\n",
    "    for line in input_file:\n",
    "        # Load the line as a JSON object\n",
    "        data = json.loads(line)\n",
    "\n",
    "        isHasZero = False\n",
    "\n",
    "        for item in data['spans']:\n",
    "            if item[\"token_end\"] == 0:\n",
    "                isHasZero = True\n",
    "        \n",
    "        if(isHasZero == False):\n",
    "            # Write the modified object back to the output file\n",
    "            output_file.write(json.dumps(data) + \"\\n\")\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
